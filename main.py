import asyncio
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from dotenv import load_dotenv
load_dotenv()

app = FastAPI()

# Temporary in-memory dictionary for demonstration. 
# In production, replace ChatMessageHistory with PostgresChatMessageHistory, Redis, etc.
store = {}

# here we populate the dictionary with the key being session id and value being the chatmessagehistory
def get_session_history(session_id: str) -> BaseChatMessageHistory:
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

# enable streaming true
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", streaming=True)

# define the prompt, leaving a placeholder for the injected history
prompt = ChatPromptTemplate.from_messages([
    ("system", """You are an accessible, helpful, and direct AI assistant designed for a mobile app used by mute and deaf individuals whose primary language is Indian Sign Language (ISL).

Follow these strict rules for every response:
1. Forgive Grammar and Syntax: The user may type using ISL syntax or omit connecting words (articles, prepositions). Focus entirely on their intent. Never correct their grammar or point out typos.
2. Plain and Direct Language: Use simple, everyday vocabulary. Keep sentences short. Do not use idioms, metaphors, sarcasm, or overly complex phrasing.
3. Highly Visual Formatting: Break up your responses. Use bullet points, numbered lists, and bold text for key information. Avoid long paragraphs; make everything skimmable.
4. Professional Tone: Be empathetic and helpful, but do not be patronizing or over-apologetic. Focus strictly on delivering the information or completing the task.hello. how do sign 'hello' in isl?
5. If user is talking in hindhi reply in hindhi"""
),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{question}"),
])

chain = prompt | llm

# Wrap the chain with the history manager
conversational_chain = RunnableWithMessageHistory(
    chain,
    get_session_history,
    input_messages_key="question",
    history_messages_key="history",
)

# pydantic model for the request
class ChatRequest(BaseModel):
    message: str

# api endpoint. async and handles response streaming somehow
@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    static_session_id = "default_test_session"
    async def generate_response():
        # .astream() yields chunks as they are generated by Gemini
        async for chunk in conversational_chain.astream(
            {"question": request.message},
            config={"configurable": {"session_id": static_session_id}}
        ):
            # Format the chunk as a Server-Sent Event (SSE)
            yield f"data: {chunk.content}\n\n"
        
        # Optional: a completion flag for the frontend
        yield "data: [DONE]\n\n"

    return StreamingResponse(generate_response(), media_type="text/event-stream")